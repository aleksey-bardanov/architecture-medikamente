## Архитектура информационной системы Медикаменте

### Условности

В представленных диаграммах основное внимание уделено обработке данных, поэтому на схемах не отображены некоторые контейнеры, связи и действующие лица, в частности:
- кассир и кассовый аппарат
- в качестве сервис авторизации пользователей
- сервис уведомлений
- балансировщик нагрузки
- системы сбора логов и мониторинга
- системы с которыми интегрирован платежный шлюз
- соединения с Apache Ranger портала сотрудников, систем 1C и Apache Spark

### Описание решения

#### Хранение данных

Для обработки и хранения данных выбран подход ETL с хранилищем типа Lakehouse. Для реализации были выбраны продукты из экосистемы Hadoop:

- HDFS (Hadoop Distributed File System) - центральное хранилище данных, где хранятся все данные системы
- Apache Hive - слой для работы с данными через SQL-подобные запросы, для CRM
- Apache Spark - слой обработки данных, который обеспечивает быструю обработку данных для аналитиков
- Apache NiFi - точка входа данных в систему
- Apache Atlas - инструмент для разметки данных
- Apache Ranger - инструмент для ограничения доступа к данным 

Эти инструменты и подходы выбраны потому что:

- требуется быстро запустить MVP, а это инструменты из одной экосистемы и должны показывать высокий уровень синергии в работе
- стек удовлетворяет нефункциональным требованиям: масштабируемость, конфигурируемость, безопасность, сопроваждаемость
- ролевая модель доступа, интеграция с существующими системами и линеаризация данных доступны "из коробки"
- процессы обработки данных легко менять в соответствии с требованиями бизнеса 

#### Загрузка данных в систему и получение доступа к ним

В предложенной архитектуре сервисы (в том числе 1С) используют кластер Hadoop для загрузки и получения доступа к данным через Apache Hive, что позволяет работать с хранилищем как с реляционной базой данных. 

Сторонние сервисы и системы могут передавать данные в хранилище через Apache NiFi. Также выбранный инструмент позволит провести первоначальную загрузку данных в хранилище унифицировано из разрозненных источников.

Аналитики данных получают доступ к данным системы через Apache Spark.

Так как выбранное хранилище данных спроектировано так, чтобы быть масштабируемым, как и выбранная система сбора данных, а проектируемые сервисы не предполагают хранения состояния, то предложенная должна быть легко масштабируемой. Данные в хранилище предполагается размечать тегами и предоставлять доступ к ним в соответствие с правами ролей RBAC (интеграция Apache Ranger и Apache Atlas). Для шифрования данных в состоянии покоя используется Hadoop Transparent Data Encryption (TDE), а для шифрования данных при передаче – SSL/TLS.


#### Трудности и риски

- **Миграция БД 1C**. Придется перенести данные из файлов 1С в кластер Hadoop для этого существует ряд решений, таких как HSqoop, а также встроенные возможности платформы 1С. 
- **Увеличение IT отдела**. Предлагаемое решение требует значительного увеличения штата сотрудников, однако это допустимо, т.к. входит в планы компании.
- **Перевод инфраструктуры в облако**. С ростом системы для обеспечения SLA по доступности может потребоваться перенос части инфраструктуры в облако.

#### Альтернативы

- **Другой подход к хранению данных**. Альтернативой являются подходы data lake, data warehouse, data mesh. Подход lakehouse выбран потому что в системе присутствуют данные разного типа, структурированные и неструктурированные, которые нужно хранить, анализировать, а также получать к ним доступ.
- **Другой стек технологий**. Альтернативой может выступить стек технологий на основе Databricks: Databricks Lakehouse Platform, Unity Catalog, Databricks Connect. Преимущество этих продуктов заключается в том, что у них имеется официальная поддержка, гарантируется безопасность и высокая скорость внедрения. Недостатком является то, что это проприетарный продукт.
- **Интеграция с системами 1С через брокер или REST API**. В представленном решении все данные системы хранятся в кластере Hadoop, можно было бы оставить по БД на каждый из сервисов 1С и передавать данные в хранилище через Apache NiFi. При таком решении данные можно было бы как-то дополнительно обработать перед загрузкой в хранилище.  
- **Собственный платежный шлюз**. В задании указано, что планируется разработка собственного платежного шлюза. Предлагаю использовать готовое решение, так как основной бизнес компании не разработка программных продуктов.